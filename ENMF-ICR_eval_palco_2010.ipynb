{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENMF-ICR Evaluation palco_2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np \n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as L\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from numba import njit\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from data import ImplicitData\n",
    "import pandas as pd\n",
    "from BISGD import BISGD\n",
    "from ENMF_ICR import ENMF_ICR\n",
    "from collections import defaultdict\n",
    "from eval_implicit import EvalPrequential\n",
    "from datetime import datetime\n",
    "import getopt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def sumvector(V,x):\n",
    "    result = []\n",
    "    for v in V:\n",
    "        temp = v + x\n",
    "        result.append(temp)\n",
    "    return result    \n",
    "\n",
    "def multvector(x,V):\n",
    "    result = []\n",
    "    for v in V:\n",
    "        temp = v * x\n",
    "        result.append(temp)\n",
    "    return result    \n",
    "\n",
    "def TransformVec(V):\n",
    "  \n",
    "    #new = normalize(V[:,np.newaxis], axis=0).ravel()\n",
    "    for i in range(len(V)):\n",
    "        V[i] = sigmoid(V[i])\n",
    "    D = LA.norm(V)\n",
    "    D=1/D\n",
    "    new = D * V\n",
    "  \n",
    "\n",
    "    return new\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmelo/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  track_id            timestamp\n",
      "0         4220     31313  2010-01-01 00:10:36\n",
      "1         4220     29567  2010-01-01 00:13:07\n",
      "2         4220     31313  2010-01-01 00:13:18\n",
      "3         3970     34925  2010-01-01 00:39:21\n",
      "4         6258     18106  2010-01-01 00:46:25\n",
      "...        ...       ...                  ...\n",
      "58795    47350      9040  2010-01-24 11:04:20\n",
      "58796    47350      9034  2010-01-24 11:04:32\n",
      "58797    47350      9032  2010-01-24 11:05:09\n",
      "58798    47350      9030  2010-01-24 11:05:11\n",
      "58799    47350      9031  2010-01-24 11:05:17\n",
      "\n",
      "[58800 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./')\n",
    "configPath = 'config'\n",
    "dataPath = 'palco_2010.tsv'\n",
    "\n",
    "\n",
    "Data = []\n",
    "data = pd.read_csv(\"palco_2010.tsv\",\"\\t\")\n",
    "data = data.head(n=58800)\n",
    "print(data)\n",
    "Data = data.values.tolist()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmelo/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 2022-09-21 21:38:57.356720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if user not in self.userset:\n",
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:62: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if item not in self.itemset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmean(resuls[Recall@20]) 0.196693657219973\n",
      "end time 2022-09-21 23:31:54.020512\n",
      "run time 1:52:56.663792\n",
      "\n",
      "get tuple 9.497223686585538e-06\n",
      "recommend 0.6848495746591957\n",
      "eval_point 2.9749675640049573e-05\n",
      "update 0.004598371962139776\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./')\n",
    "configPath = 'config'\n",
    "dataPath = 'palco_2010.tsv'\n",
    "\n",
    "\n",
    "Data = []\n",
    "data = pd.read_csv(\"palco_2010.tsv\",\"\\t\")\n",
    "\n",
    "Data = data.values.tolist()\n",
    "\n",
    "Data_Transpose = np.transpose(Data)\n",
    "stream = ImplicitData(Data_Transpose[0],Data_Transpose[1])\n",
    "\n",
    "num_clusters = 8\n",
    "cl_num_iterations = 25\n",
    "cl_learn_rate = 0.001\n",
    "cl_regularization = 0.0001\n",
    "num_factors = 160\n",
    "num_iter = 4\n",
    "learn_rate = 0.5\n",
    "regularization = 0.4\n",
    "model = ENMF_ICR(ImplicitData([],[]), num_clusters, cl_num_iterations, cl_learn_rate, cl_regularization, \n",
    "    num_factors, num_iter, learn_rate, regularization, random_seed = 10)\n",
    "eval = EvalPrequential(model,stream, metrics = [\"Recall@20\"])\n",
    "start_recommend = datetime.now()\n",
    "print('start time', start_recommend)\n",
    "\n",
    "results=eval.EvaluateTime(0,stream.size, 100)\n",
    "\n",
    "print('npmean(resuls[Recall@20])', np.mean(results['Recall@20']))\n",
    "end_recommend = datetime.now()\n",
    "print('end time', end_recommend)\n",
    "\n",
    "tempo = end_recommend - start_recommend\n",
    "\n",
    "print('run time', tempo)\n",
    "print('')\n",
    "print('get tuple',np.mean(results['time_get_tuple']))\n",
    "print('recommend',np.mean(results['time_recommend']))\n",
    "print('eval_point',np.mean(results['time_eval_point']))\n",
    "print('update',np.mean(results['time_update'])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampled datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### palco_sample5_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  user_id  track_id            timestamp\n",
      "0              87     4110     39059  2010-01-01 10:13:30\n",
      "1              88     4110     36931  2010-01-01 10:14:19\n",
      "2              89     4110     36360  2010-01-01 10:14:28\n",
      "3              90     4110     38603  2010-01-01 10:14:31\n",
      "4              91     4110     39062  2010-01-01 10:18:30\n",
      "...           ...      ...       ...                  ...\n",
      "32570      588644    66046     60491  2010-12-31 18:54:15\n",
      "32571      588649    47201     51413  2010-12-31 18:56:51\n",
      "32572      588650    66046     57049  2010-12-31 18:58:39\n",
      "32573      588652    47201     74940  2010-12-31 19:01:51\n",
      "32574      588658    47201     74798  2010-12-31 19:05:27\n",
      "\n",
      "[32575 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "\n",
    "Data = []\n",
    "data = pd.read_csv(\"palco_sample5_1.csv\")\n",
    "print(data)\n",
    "Data = data.values.tolist()\n",
    "\n",
    "Data = Data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 2022-09-20 19:03:22.550533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if user not in self.userset:\n",
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:62: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if item not in self.itemset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmean(resuls[Recall@20]) 0.13803680981595093\n",
      "end time 2022-09-20 19:05:30.502569\n",
      "run time 0:02:07.952036\n",
      "\n",
      "get tuple 6.194652506547891e-06\n",
      "recommend 0.17187089203325517\n",
      "eval_point 3.338664587290009e-05\n",
      "update 0.0021979312120298145\n"
     ]
    }
   ],
   "source": [
    "Data_Transpose = np.transpose(Data)\n",
    "stream = ImplicitData(Data_Transpose[1],Data_Transpose[2])\n",
    "\n",
    "num_clusters = 8\n",
    "cl_num_iterations = 25\n",
    "cl_learn_rate = 0.001\n",
    "cl_regularization = 0.0001\n",
    "num_factors = 160\n",
    "num_iter = 4\n",
    "learn_rate = 0.5\n",
    "regularization = 0.4\n",
    "model = ENMF_ICR(ImplicitData([],[]), num_clusters, cl_num_iterations, cl_learn_rate, cl_regularization, \n",
    "    num_factors, num_iter, learn_rate, regularization, random_seed = 10)\n",
    "eval = EvalPrequential(model,stream, metrics = [\"Recall@20\"])\n",
    "start_recommend = datetime.now()\n",
    "print('start time', start_recommend)\n",
    "\n",
    "results=eval.EvaluateTime(0,stream.size, 100)\n",
    "\n",
    "print('npmean(resuls[Recall@20])', np.mean(results['Recall@20']))\n",
    "end_recommend = datetime.now()\n",
    "print('end time', end_recommend)\n",
    "\n",
    "tempo = end_recommend - start_recommend\n",
    "\n",
    "print('run time', tempo)\n",
    "print('')\n",
    "print('get tuple',np.mean(results['time_get_tuple']))\n",
    "print('recommend',np.mean(results['time_recommend']))\n",
    "print('eval_point',np.mean(results['time_eval_point']))\n",
    "print('update',np.mean(results['time_update'])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### palco_sample5_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  user_id  track_id            timestamp\n",
      "0               9    40958      8826  2010-01-01 01:22:39\n",
      "1              10    40958      8825  2010-01-01 01:22:50\n",
      "2              11    40958      8836  2010-01-01 01:22:58\n",
      "3              12    40958     19882  2010-01-01 01:23:26\n",
      "4              13    40958     27698  2010-01-01 01:23:28\n",
      "...           ...      ...       ...                  ...\n",
      "27471      588433       66     28216  2010-12-31 17:44:54\n",
      "27472      588439       66     28217  2010-12-31 17:48:38\n",
      "27473      588443       66     28218  2010-12-31 17:51:16\n",
      "27474      588448       66     28216  2010-12-31 17:55:11\n",
      "27475      588450       66     28217  2010-12-31 17:58:54\n",
      "\n",
      "[27476 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "\n",
    "Data = []\n",
    "data = pd.read_csv(\"palco_sample5_2.csv\")\n",
    "print(data)\n",
    "Data = data.values.tolist()\n",
    "\n",
    "Data = Data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 2022-09-20 19:05:31.061245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if user not in self.userset:\n",
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:62: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if item not in self.itemset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmean(resuls[Recall@20]) 0.10283687943262411\n",
      "end time 2022-09-20 19:07:13.882024\n",
      "run time 0:01:42.820779\n",
      "\n",
      "get tuple 5.710226931932083e-06\n",
      "recommend 0.16656345932196218\n",
      "eval_point 3.2152689940540504e-05\n",
      "update 0.0020234509139195477\n"
     ]
    }
   ],
   "source": [
    "Data_Transpose = np.transpose(Data)\n",
    "stream = ImplicitData(Data_Transpose[1],Data_Transpose[2])\n",
    "\n",
    "num_clusters = 8\n",
    "cl_num_iterations = 25\n",
    "cl_learn_rate = 0.001\n",
    "cl_regularization = 0.0001\n",
    "num_factors = 160\n",
    "num_iter = 4\n",
    "learn_rate = 0.5\n",
    "regularization = 0.4\n",
    "model = ENMF_ICR(ImplicitData([],[]), num_clusters, cl_num_iterations, cl_learn_rate, cl_regularization, \n",
    "    num_factors, num_iter, learn_rate, regularization, random_seed = 10)\n",
    "eval = EvalPrequential(model,stream, metrics = [\"Recall@20\"])\n",
    "start_recommend = datetime.now()\n",
    "print('start time', start_recommend)\n",
    "\n",
    "results=eval.EvaluateTime(0,stream.size, 100)\n",
    "\n",
    "print('npmean(resuls[Recall@20])', np.mean(results['Recall@20']))\n",
    "end_recommend = datetime.now()\n",
    "print('end time', end_recommend)\n",
    "\n",
    "tempo = end_recommend - start_recommend\n",
    "\n",
    "print('run time', tempo)\n",
    "print('')\n",
    "print('get tuple',np.mean(results['time_get_tuple']))\n",
    "print('recommend',np.mean(results['time_recommend']))\n",
    "print('eval_point',np.mean(results['time_eval_point']))\n",
    "print('update',np.mean(results['time_update'])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### palco_sample5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  user_id  track_id            timestamp\n",
      "0            1908     4401      9058  2010-01-02 02:23:45\n",
      "1            1912     4401      9058  2010-01-02 02:23:54\n",
      "2            1914     4401      9058  2010-01-02 02:24:00\n",
      "3            1917     4401      9061  2010-01-02 02:25:13\n",
      "4            1938     4401      9060  2010-01-02 02:35:41\n",
      "...           ...      ...       ...                  ...\n",
      "30796      588678    68503     74879  2010-12-31 19:37:09\n",
      "30797      588679    68503     74512  2010-12-31 19:39:50\n",
      "30798      588680    68503     73508  2010-12-31 19:39:51\n",
      "30799      588681    68503     70401  2010-12-31 19:39:55\n",
      "30800      588787    54903      3390  2010-12-31 21:35:26\n",
      "\n",
      "[30801 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "\n",
    "Data = []\n",
    "data = pd.read_csv(\"palco_sample5_3.csv\")\n",
    "print(data)\n",
    "Data = data.values.tolist()\n",
    "\n",
    "Data = Data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 2022-09-20 19:07:14.238732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if user not in self.userset:\n",
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:62: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if item not in self.itemset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmean(resuls[Recall@20]) 0.12982456140350876\n",
      "end time 2022-09-20 19:09:17.092262\n",
      "run time 0:02:02.853530\n",
      "\n",
      "get tuple 5.82981419253659e-06\n",
      "recommend 0.2046658432274534\n",
      "eval_point 3.2211604871247945e-05\n",
      "update 0.002085535866873605\n"
     ]
    }
   ],
   "source": [
    "Data_Transpose = np.transpose(Data)\n",
    "stream = ImplicitData(Data_Transpose[1],Data_Transpose[2])\n",
    "\n",
    "num_clusters = 8\n",
    "cl_num_iterations = 25\n",
    "cl_learn_rate = 0.001\n",
    "cl_regularization = 0.0001\n",
    "num_factors = 160\n",
    "num_iter = 4\n",
    "learn_rate = 0.5\n",
    "regularization = 0.4\n",
    "model = ENMF_ICR(ImplicitData([],[]), num_clusters, cl_num_iterations, cl_learn_rate, cl_regularization, \n",
    "    num_factors, num_iter, learn_rate, regularization, random_seed = 10)\n",
    "eval = EvalPrequential(model,stream, metrics = [\"Recall@20\"])\n",
    "start_recommend = datetime.now()\n",
    "print('start time', start_recommend)\n",
    "\n",
    "results=eval.EvaluateTime(0,stream.size, 100)\n",
    "\n",
    "print('npmean(resuls[Recall@20])', np.mean(results['Recall@20']))\n",
    "end_recommend = datetime.now()\n",
    "print('end time', end_recommend)\n",
    "\n",
    "tempo = end_recommend - start_recommend\n",
    "\n",
    "print('run time', tempo)\n",
    "print('')\n",
    "print('get tuple',np.mean(results['time_get_tuple']))\n",
    "print('recommend',np.mean(results['time_recommend']))\n",
    "print('eval_point',np.mean(results['time_eval_point']))\n",
    "print('update',np.mean(results['time_update'])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### palco_sample5_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  user_id  track_id            timestamp\n",
      "0               5     6258     18106  2010-01-01 00:46:25\n",
      "1             254    46286     32670  2010-01-01 13:07:15\n",
      "2             257    46286     36970  2010-01-01 13:08:05\n",
      "3             323      927     27213  2010-01-01 13:52:23\n",
      "4             325      927      1123  2010-01-01 13:53:08\n",
      "...           ...      ...       ...                  ...\n",
      "31457      588391    67485     66079  2010-12-31 17:20:40\n",
      "31458      588392    67485     66080  2010-12-31 17:22:07\n",
      "31459      588396    67485     66081  2010-12-31 17:24:42\n",
      "31460      588398    67485     66082  2010-12-31 17:27:11\n",
      "31461      588401    67485     65764  2010-12-31 17:28:08\n",
      "\n",
      "[31462 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "\n",
    "Data = []\n",
    "data = pd.read_csv(\"palco_sample5_4.csv\")\n",
    "print(data)\n",
    "Data = data.values.tolist()\n",
    "\n",
    "Data = Data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 2022-09-20 20:15:38.965689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if user not in self.userset:\n",
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:62: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if item not in self.itemset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmean(resuls[Recall@20]) 0.14482758620689656\n",
      "end time 2022-09-20 20:17:25.573037\n",
      "run time 0:01:46.607348\n",
      "\n",
      "get tuple 5.62492334957492e-06\n",
      "recommend 0.15182369330833698\n",
      "eval_point 3.075846310319572e-05\n",
      "update 0.001979977406843427\n"
     ]
    }
   ],
   "source": [
    "Data_Transpose = np.transpose(Data)\n",
    "stream = ImplicitData(Data_Transpose[1],Data_Transpose[2])\n",
    "\n",
    "num_clusters = 8\n",
    "cl_num_iterations = 25\n",
    "cl_learn_rate = 0.001\n",
    "cl_regularization = 0.0001\n",
    "num_factors = 160\n",
    "num_iter = 4\n",
    "learn_rate = 0.5\n",
    "regularization = 0.4\n",
    "model = ENMF_ICR(ImplicitData([],[]), num_clusters, cl_num_iterations, cl_learn_rate, cl_regularization, \n",
    "    num_factors, num_iter, learn_rate, regularization, random_seed = 10)\n",
    "eval = EvalPrequential(model,stream, metrics = [\"Recall@20\"])\n",
    "start_recommend = datetime.now()\n",
    "print('start time', start_recommend)\n",
    "\n",
    "results=eval.EvaluateTime(0,stream.size, 100)\n",
    "\n",
    "print('npmean(resuls[Recall@20])', np.mean(results['Recall@20']))\n",
    "end_recommend = datetime.now()\n",
    "print('end time', end_recommend)\n",
    "\n",
    "tempo = end_recommend - start_recommend\n",
    "\n",
    "print('run time', tempo)\n",
    "print('')\n",
    "print('get tuple',np.mean(results['time_get_tuple']))\n",
    "print('recommend',np.mean(results['time_recommend']))\n",
    "print('eval_point',np.mean(results['time_eval_point']))\n",
    "print('update',np.mean(results['time_update'])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### palco_sample5_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  user_id  track_id            timestamp\n",
      "0              54     3898     35623  2010-01-01 03:33:50\n",
      "1              55     3898       543  2010-01-01 03:33:57\n",
      "2              56     3898       545  2010-01-01 03:34:25\n",
      "3              59     3898       681  2010-01-01 03:35:46\n",
      "4              73     3898       550  2010-01-01 03:40:30\n",
      "...           ...      ...       ...                  ...\n",
      "28204      588645     2704     74092  2010-12-31 18:54:19\n",
      "28205      588646     2704     74095  2010-12-31 18:54:30\n",
      "28206      588654     2704     70876  2010-12-31 19:03:19\n",
      "28207      588805    38854     26042  2010-12-31 21:49:17\n",
      "28208      588810    38854     24985  2010-12-31 21:57:49\n",
      "\n",
      "[28209 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('./')\n",
    "\n",
    "\n",
    "\n",
    "Data = []\n",
    "data = pd.read_csv(\"palco_sample5_5.csv\")\n",
    "print(data)\n",
    "Data = data.values.tolist()\n",
    "\n",
    "Data = Data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 2022-09-20 19:09:18.440308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if user not in self.userset:\n",
      "/home/mmelo/NMF|BISGD/data/implicit_data.py:62: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if item not in self.itemset:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npmean(resuls[Recall@20]) 0.11678832116788321\n",
      "end time 2022-09-20 19:11:05.097364\n",
      "run time 0:01:46.657056\n",
      "\n",
      "get tuple 5.860340169256409e-06\n",
      "recommend 0.17378961169806711\n",
      "eval_point 3.381628189643804e-05\n",
      "update 0.0020834200773060625\n"
     ]
    }
   ],
   "source": [
    "Data_Transpose = np.transpose(Data)\n",
    "stream = ImplicitData(Data_Transpose[1],Data_Transpose[2])\n",
    "\n",
    "num_clusters = 8\n",
    "cl_num_iterations = 25\n",
    "cl_learn_rate = 0.001\n",
    "cl_regularization = 0.0001\n",
    "num_factors = 160\n",
    "num_iter = 4\n",
    "learn_rate = 0.5\n",
    "regularization = 0.4\n",
    "model = ENMF_ICR(ImplicitData([],[]), num_clusters, cl_num_iterations, cl_learn_rate, cl_regularization, \n",
    "    num_factors, num_iter, learn_rate, regularization, random_seed = 10)\n",
    "eval = EvalPrequential(model,stream, metrics = [\"Recall@20\"])\n",
    "start_recommend = datetime.now()\n",
    "print('start time', start_recommend)\n",
    "\n",
    "results=eval.EvaluateTime(0,stream.size, 100)\n",
    "\n",
    "print('npmean(resuls[Recall@20])', np.mean(results['Recall@20']))\n",
    "end_recommend = datetime.now()\n",
    "print('end time', end_recommend)\n",
    "\n",
    "tempo = end_recommend - start_recommend\n",
    "\n",
    "print('run time', tempo)\n",
    "print('')\n",
    "print('get tuple',np.mean(results['time_get_tuple']))\n",
    "print('recommend',np.mean(results['time_recommend']))\n",
    "print('eval_point',np.mean(results['time_eval_point']))\n",
    "print('update',np.mean(results['time_update'])) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
